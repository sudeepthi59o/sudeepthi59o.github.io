<!doctype html><style>html{height:100vh}body{min-height:100vh;display:grid;grid-template-rows:1fr auto}.footer{grid-row-start:2;grid-row-end:3}</style><html lang=en-gb><head><meta charset=utf-8><title>Sudeepthi Rebbalapalli</title>
<meta name=viewport content="width=device-width,initial-scale=1"><meta name=description property="og:description" content="Deep learning model using CNNs to detect early-onset Parkinson’s from speech data"><meta name=image property="og:image" content="/"><meta name=author content="Sudeepthi Rebbalapalli"><meta name=generator content="Hugo 0.134.2"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/uikit@3.2.6/dist/css/uikit.min.css><link rel=stylesheet href=/css/style.min.css integrity media=screen><link rel=stylesheet href=/css/syntax.min.css integrity media=screen><script src=https://cdn.jsdelivr.net/npm/mailgo@0.9.14/dist/mailgo.min.js defer></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest></head><body class=portfolio><div class=wrapper><div uk-sticky="sel-target: .uk-navbar-container; cls-active: uk-navbar-sticky; bottom: #transparent-sticky-navbar"><nav class="uk-navbar-container uk-margin uk-light" uk-navbar="mode: click;" style=background-color:#333;padding-right:3rem><div class=uk-navbar-right><ul class="uk-navbar-nav uk-visible@s"><li><a class="uk-text-bold uk-text-white" href=/>Home</a></li><li><a class="uk-text-bold uk-text-white" href=/about>About</a></li><li class=uk-active><a class="uk-text-bold uk-text-white" href=/portfolio>Projects</a></li><li><a class="uk-text-bold uk-text-white" href=/contact>Contact</a></li></ul><a class="uk-navbar-toggle uk-hidden@s" uk-toggle="target: #sidenav" uk-navbar-toggle-icon href=#></a></div></nav></div><div id=sidenav uk-offcanvas="overlay: true"><div class="uk-offcanvas-bar uk-flex uk-flex-column"><ul class="uk-nav uk-nav-primary uk-nav-center uk-margin-auto-vertical"><li><a style=font-size:18px href=https://sudeepthi59o.github.io/>Home</a></li><li><a style=font-size:18px href=/about>About</a></li><li class=uk-active><a style=font-size:18px href=/portfolio>Projects</a></li><li><a style=font-size:18px href=/contact>Contact</a></li></ul></div></div><style>p{margin:0}.people-wrap{display:inline-flex;margin-top:10px}.people-image{display:block;border-radius:50%}.people{margin-left:20px;margin-right:20px}.name{margin:auto}h1,h2,h3,h4,h5,h6{color:#000;font-family:Roboto,sans-serif;line-height:1.2;margin-top:2rem}.content img{box-shadow:0 4px 8px rgba(0,0,0,.2),0 6px 20px rgba(0,0,0,.19);display:block;margin-left:auto;margin-right:auto;margin-bottom:30px}p{margin-bottom:1em}body p:last-child{margin-bottom:0}img.skills{height:80px}@media only screen and (min-width:960px){.content img{max-width:60vw;max-height:60vh}.content img{max-width:60vw;max-height:60vh}}.content{width:90vw;max-width:1200px}table{font-family:arial,sans-serif;border-collapse:collapse;width:100%}td,th{border:1px solid #ddd;text-align:left;padding:8px}</style><section><div class="uk-container uk-margin-large-bottom uk-margin-medium-top"><h1 class="uk-text-center uk-heading-medium">Early Onset Parkinson's Detection from Speech Data</h1><p class="uk-text-center uk-text-lead">Deep learning model using CNNs to detect early-onset Parkinson’s from speech data</p><p class=uk-text-center>Published on Apr 12, 2025</p><p class=uk-text-center>Reading time: 3 minutes.</p><div class="uk-child-width-1-4@m uk-child-width-1-2@s uk-text-center uk-flex-center uk-grid-large uk-margin-small-top" uk-grid></div><hr class=full-width><h2 class="uk-text-center uk-heading-small">Built with</h2><section><div class=uk-container><div class="uk-child-width-1-6@l uk-child-width-1-3@m uk-child-width-1-3@s uk-child-width-1-2 uk-text-center uk-flex-center" uk-grid><div class=imagemargin><a href=https://www.python.org/><img class="contain skills" src="https://ik.imagekit.io/ys4gkaixy/Skills/Python_logo_01.svg?updatedAt=1744511052787" alt=Python loading=lazy style=cursor:pointer></a></div><div class=imagemargin><a href=https://keras.io><img class="contain skills" src=https://cdn.jsdelivr.net/gh/devicons/devicon@latest/icons/keras/keras-original.svg alt=Keras loading=lazy style=cursor:pointer></a></div><div class=imagemargin><a href=https://librosa.org/><img class="contain skills" src="https://ik.imagekit.io/ys4gkaixy/sound-waves-svgrepo-com.svg?updatedAt=1745129088650" alt=Librosa loading=lazy style=cursor:pointer></a></div><div class=imagemargin><a href=https://en.wikipedia.org/wiki/Convolutional_neural_network><img class="contain skills" src="https://ik.imagekit.io/ys4gkaixy/Neural_network.svg?updatedAt=1744744987487" alt=CNN loading=lazy style=cursor:pointer></a></div></div></div></section><hr class=full-width><div class=content><h2 id=overview><strong>Overview</strong></h2><p>This project implements an end-to-end deep learning model using <strong>convolutional neural networks (CNNs)</strong> to detect <strong>early-onset Parkinson&rsquo;s Disease (PD)</strong> from speech data. By leveraging <strong>Mel spectrograms</strong>—visual and mathematical representations of sound frequencies over time, to reflect human hearing perception—our model extracts features that help identify vocal indicators of PD.</p><p>The work builds on methodologies by Quan et al. and evaluates their applicability to a real-world Italian dataset. Tools like <strong>Librosa</strong> were used for audio processing, and <strong>NeuroSpeech</strong>, a software tool designed to assist medical professionals in evaluating biomarkers of neurodegenerative diseases through speech analysis, was explored to identify the key factors in detecting PD from speech.</p><p>The project was completed as part of graduate coursework, supported by an international collaboration grant. It involved a partnership with a researcher and doctor from an Indian hospital, providing expert insights into Parkinson’s speech biomarkers.</p><hr><h2 id=motivation><strong>Motivation</strong></h2><p>Early detection of PD, especially in its early-onset form, is challenging due to subtle symptoms. Since ~90% of PD patients exhibit speech impairments, analyzing vocal characteristics becomes a promising, non-invasive method for early detection.</p><hr><h2 id=techniques-used><strong>Techniques Used</strong></h2><ul><li>Following the architecture proposed by Quan et al., the model uses a <strong>two-stage CNN</strong> to detect Parkinson’s Disease from speech:<ul><li><strong>Time-Distributed 2D CNN</strong>: Processes overlapping segments of log Mel-spectrograms to extract local spatial features while preserving temporal structure.</li><li><strong>1D CNN</strong>: Captures temporal patterns such as jitter from the flattened 2D-CNN outputs.</li><li><strong>Final Layers</strong>: Fully connected layers classify the extracted features to predict PD presence.</li></ul></li><li><strong>Mel-spectrograms</strong> Used as image-like inputs, representing the mathematical features of sound</li><li><strong>Librosa</strong>: Utlized for audio processing and Mel spectrogram generation.</li><li><strong>NeuroSpeech</strong>: Used for analyzing key speech features in PD patients, , focusing on phonation, articulation, prosody, and intelligibility.</li><li><strong>Datasets</strong>: Speech data collected in Italian, Telugu, and English</li></ul><hr><h2 id=project-workflow><strong>Project Workflow</strong></h2><p>The overall workflow of the model, from speech input to Parkinson’s detection, is outlined below.</p><p><img src=/images/PD_Detection_Workflow.svg alt=Workflow></p><hr><h2 id=dataset-and-processing><strong>Dataset and Processing</strong></h2><ul><li><strong>Italian Dataset</strong>: 394 HC samples and 437 PD samples from 65 participants.</li><li><strong>Telugu Dataset</strong>: 24 samples from 8 participants under varied noise conditions (created by the class).</li><li><strong>English Dataset</strong>: KCL Hospital phone-based recordings with detailed PD annotations.</li></ul><p>Example of a Mel spectrogram generated from raw speech data:
Left: Heatmap representation, Right: Frequency matrix</p><p><img src=/images/Mel_spectrogram.png alt=Mel_Spectrogram></p><hr><h2 id=tools--libraries><strong>Tools & Libraries</strong></h2><ul><li>Python</li><li>TensorFlow / Keras</li><li>Librosa</li><li>NeuroSpeech</li><li>Matplotlib / Seaborn (for visualization)</li></ul><hr><h2 id=results><strong>Results</strong></h2><ul><li>Achieved <strong>~98% validation accuracy</strong> on Italian speech samples using improved preprocessing (2,000-frame spectrogram segments).</li><li>Found <strong>low-frequency spectrogram features</strong> to be most indicative of PD.</li><li>Cross-language testing revealed poor generalizability, highlighting the need for <strong>language-specific models</strong> when applying deep learning.</li></ul><hr><h2 id=challenges--insights><strong>Challenges & Insights</strong></h2><ul><li><strong>CNNs</strong>, while powerful, suffer from a lack of interpretability, which is a significant concern in clinical settings.</li><li><strong>Cross-language models</strong> struggle without balanced training data, limiting their effectiveness.</li><li>Future improvements include:<ul><li>Expanding training sets for multilingual support</li><li>Exploring more interpretable machine learning algorithms like trees or building tools like NeuroSpeech, which directly extracts key speech features (such as articulation rate, pitch variability, and speech clarity) from audio and compares them against a database of healthy control (HC) and PD patient data to determine whether they fall within a normal or abnormal range.</li></ul></li></ul><hr><h2 id=extras-resources><strong>Extras/ Resources</strong></h2><ul><li>Read full project report here - <a href=/Parkinsons_Approach_Report.pdf>PDF</a></li><li>Exploratory notebooks for Librosa audio processing - <a href=/Librosa_Feature_Extraction.pdf>Notebook</a></li></ul><hr><h2 id=references><strong>References</strong></h2><ul><li><a href=https://www.sciencedirect.com/science/article/abs/pii/S0208521622000341>Quan et al., 2022: <em>End-to-End Deep Learning for PD Speech Detection</em></a></li><li><a href=https://ieee-dataport.org/open-access/italian-parkinsons-voice-and-speech>Dimauro & Girardi, 2019: <em>Italian Parkinson’s Voice and Speech Dataset</em></a></li><li><a href=https://www.sciencedirect.com/science/article/pii/S105120041730146X>Orozco-Arroyave et al., 2018: <em>NeuroSpeech Tool</em></a></li><li><a href="https://explore.openaire.eu/search/dataset?pid=10.5281%2Fzenodo.2867215">Jaeger et al., 2019: <em>KCL English Dataset (MDVR-KCL)</em></a></li></ul><hr><h2 id=takeaway>Takeaway</h2><p>Deep learning shows promise in detecting early-onset Parkinson’s from speech, but challenges in interpretability and cross-language generalization remain. Future advancements should focus on multilingual datasets and more interpretable approaches.</p><blockquote><p>Code available upon request</p></blockquote></div></div></div></section></div><footer class=footer><div class=uk-container><div class="uk-grid-small uk-child-width-1-4@m uk-text-center uk-flex-center uk-margin-medium-bottom" uk-grid><div class=uk-margin-small-bottom><h5 class=uk-margin-small-bottom>Email</h5><a href=mailto:sudeepthi59o@gmail.com>sudeepthi59o@gmail.com</a></div><div><h5 class=uk-margin-small-bottom>Address</h5><div uk-lightbox><a href=https://maps.app.goo.gl/skKWiTuWiZYaoM1L8 data-caption="Manchester, CT, USA" data-type=iframe>Manchester, CT, USA</a></div></div></div><div class="footer-copyright uk-text-center" style=padding-bottom:1rem><img loading=lazy src=https://mirrors.creativecommons.org/presskit/icons/cc.svg style=height:1.2em;width:1.2em alt="Creative Commons">
<img loading=lazy src=https://mirrors.creativecommons.org/presskit/icons/by.svg style=height:1.2em;width:1.2em alt=CC-BY>
2025
Sudeepthi Rebbalapalli</div></div></footer><script src=https://cdn.jsdelivr.net/npm/uikit@3.2.6/dist/js/uikit.min.js></script><script src=https://cdn.jsdelivr.net/npm/uikit@3.2.6/dist/js/uikit-icons.min.js></script></body></html>